# Panorama T√©cnico do Sistema RAG (Health Guardian)

> **Status da An√°lise**: 05/01/2026
> **Contexto**: Migra√ß√£o para arquitetura Ag√™ntica (Estilo Trae/Cursor)

## 1. Arquitetura Atual (As-Is)

Ao contr√°rio das regras de projeto antigas (que citavam Django), o sistema atual opera em **Node.js (Express) + Sequelize**.

### üß† Core do RAG (`backend/src/services/rag`)
O sistema possui um pipeline de recupera√ß√£o extremamente maduro e avan√ßado ("State of the Art" para implementa√ß√µes locais).

*   **Modelo de Embedding**: `bge-m3` (via Ollama).
*   **Vector Database**: PostgreSQL com `pgvector` (Tabela `patient_documents`).
*   **Estrat√©gia de Busca**: H√≠brida (Vetorial + L√©xica).
    1.  **Busca Vetorial**: Similaridade de Cosseno (`embedding <=> query`).
    2.  **Busca L√©xica**: Full-Text Search do Postgres (`websearch_to_tsquery` em portugu√™s).
    3.  **Fus√£o**: RRF (Reciprocal Rank Fusion) para combinar os rankings.
    4.  **Refinamento (Reranking)**: `Xenova/bge-reranker-v2-m3` (Transformers.js rodando local no Node) para reordenar os top-k resultados.

### üîÑ Fluxo de Dados (Pipeline)

1.  **Ingest√£o**:
    *   Dados do paciente (JSON) -> `VectorIndexer.js`.
    *   **Chunking**: `ClinicalChunkingStrategy.js` divide por eventos (Plant√£o, Exames) e sem√¢ntica.
    *   **Enriquecimento**: Gera embeddings e salva em `patient_documents`.

2.  **Consulta (Chat)**:
    *   Frontend (`AIAssistant.jsx`) envia mensagem + "Context Pills" (IDs de contextos manuais).
    *   Backend (`ClinicalRetriever.js`) expande a query.
    *   **Recupera√ß√£o**: Executa o pipeline H√≠brido -> RRF -> Rerank.
    *   **Gera√ß√£o**: LLM (Ollama) recebe o prompt com os chunks mais relevantes.

### üîó Conectores e Depend√™ncias

*   **Frontend**: `AIAssistant.jsx` gerencia o estado do chat e injeta contextos visuais ("Pills").
*   **Backend**: `ai.controller.js` orquestra a chamada entre `ollama.service.js` e `ClinicalRetriever.js`.
*   **Banco de Dados**: Tabela `patient_documents` √© a fonte da verdade para o RAG.

---

## 2. Vis√£o de Futuro: "Trae-ifica√ß√£o" (To-Be)

Para transformar o chat em uma "IDE M√©dica" (Agente Ativo), precisamos evoluir de **Leitor** (RAG Passivo) para **Ator** (Agente com Ferramentas).

### Lacunas Identificadas

1.  **Falta de "Tools" (Function Calling)**:
    *   O LLM atual apenas "fala". Ele n√£o pode "clicar" em bot√µes, agendar consultas ou calcular riscos sozinho.
    *   *Solu√ß√£o*: Implementar interface de Tools (padr√£o OpenAI/Ollama) para permitir que o agente chame `CalculatorService`, `AppointmentService`, etc.

2.  **Contexto Ativo Limitado**:
    *   O chat sabe o que foi recuperado do banco, mas n√£o sabe necessariamente "onde" o m√©dico est√° olhando na tela (qual aba, qual campo do formul√°rio).
    *   *Solu√ß√£o*: Injetar `ActiveViewContext` (metadata da rota/componente atual) no prompt do sistema.

3.  **Aus√™ncia de "Diff View" (Proposta de Altera√ß√£o)**:
    *   Em uma IDE, o agente prop√µe c√≥digo e voc√™ aceita. Na medicina, o agente deve propor **Evolu√ß√µes** ou **Prescri√ß√µes** e o m√©dico aceita ("Apply").
    *   *Solu√ß√£o*: Criar um componente de "Structured Proposal" no chat que renderiza um bot√£o "Aplicar ao Prontu√°rio".

---

## 3. Pr√≥ximos Passos (Roadmap T√°tico)

### Fase 1: Funda√ß√£o Ag√™ntica (Imediato)
- [ ] **Ferramental**: Criar `AgentToolRegistry.js` no backend para mapear fun√ß√µes do sistema (ex: `calculators`, `search_knowledge`) para JSON Schemas.
- [ ] **System Prompt**: Atualizar o prompt do Ollama para suportar pensamento estruturado (ReAct ou Tool Use).

### Fase 2: Contexto Situacional
- [ ] **Client State**: Modificar `AIAssistant.jsx` para enviar automaticamente o contexto da tela atual (ex: "Usu√°rio est√° visualizando a aba de Exames").
- [ ] **Mem√≥ria de Curto Prazo**: Implementar um buffer de "Inten√ß√£o Atual" no `ContextManager`.

### Fase 3: Interface de A√ß√£o ("Apply Button")
- [ ] **Componente de A√ß√£o**: Criar renderizadores no chat para:
    - Sugest√£o de Prescri√ß√£o (com bot√£o "Copiar para Receita").
    - Sugest√£o de Resumo de Alta (com bot√£o "Inserir na Evolu√ß√£o").