Com base na conclus√£o bem-sucedida da **Fase 1 (Camada de Anonimiza√ß√£o)** e analisando os consensos das propostas arquiteturais (especialmente a prefer√™ncia por **LlamaIndex** e **Hybrid Search**), estruturei este PRD (Product Requirements Document) para a **Fase 2**.
O foco agora √© criar a **"Ponte de Dados"**: pegar os dados seguros gerados pelo Node.js e torn√°-los pesquis√°veis pela IA.
---
# üìÑ PRD: Health Guardian - Fase 2: Ingest√£o e Vetoriza√ß√£o (RAG Core)
## 1. Vis√£o Geral e Objetivo
Construir o pipeline de **Ingest√£o, Vetoriza√ß√£o e Recupera√ß√£o (Retrieval)**. Esta fase conecta a sa√≠da anonimizada da Fase 1 ao "c√©rebro" da aplica√ß√£o.
O objetivo √© transformar os registros m√©dicos anonimizados em vetores matem√°ticos armazenados em banco de dados, permitindo busca sem√¢ntica e h√≠brida, sem expor dados sens√≠veis.
**Resultado Esperado:** Um endpoint interno capaz de receber uma pergunta (ex: "hist√≥rico de diabetes") e retornar os trechos exatos dos prontu√°rios relevantes (chunks) com suas fontes.
---
## 2. Decis√µes de Stack (Consenso)
Para esta fase, introduziremos o microservi√ßo de ML (Python) para lidar com a complexidade matem√°tica, mantendo o backend principal (Node) leve.
| Componente | Escolha T√©cnica | Justificativa |
| --- | --- | --- |
| **Vector Store** | **PostgreSQL + `pgvector**` | Mant√©m a infraestrutura unificada (mesmo DB do HG), simplifica backups e reduz custos iniciais. F√°cil migra√ß√£o para Qdrant no futuro se necess√°rio. |
| **ML Engine** | **Python (FastAPI + LlamaIndex)** | Python √© nativo para ML. LlamaIndex oferece os melhores conectores e estrat√©gias de chunking para dados m√©dicos. |
| **Embeddings** | **`nomic-embed-text`** (via Ollama) | Modelo local, alta performance (Apache 2.0), roda offline, zero custo de API. |
| **Protocolo** | **REST (HTTP)** | Comunica√ß√£o simples entre Node.js (Controller) e Python (Service). |
---
## 3. Especifica√ß√µes Funcionais
### 3.1. Infraestrutura de Dados (`pgvector`)
* **A√ß√£o:** Habilitar extens√£o `vector` no PostgreSQL existente.
* **Schema (`rag_documents`):** Tabela para armazenar os *chunks* vetoriais.
* `id`: UUID
* `patient_hash`: String (Vinculado ao ID anonimizado da Fase 1)
* `content`: Text (O trecho do prontu√°rio)
* `metadata`: JSONB (Data relativa, tipo de documento, tags)
* `embedding`: vector(768) (Sa√≠da do nomic-embed-text)
* `created_at`: Timestamp
### 3.2. Microservi√ßo de ML (`hg-ml-service`)
Um servi√ßo Python leve que exp√µe dois endpoints:
1. **POST `/ingest**`: Recebe o JSON anonimizado do Node.js, quebra em peda√ßos (chunks), gera embeddings via Ollama e salva no Postgres.
2. **POST `/retrieve**`: Recebe uma query e um `patient_hash`, converte a query em vetor e busca os chunks mais similares.
### 3.3. Estrat√©gia de Chunking (Segmenta√ß√£o)
N√£o podemos indexar o prontu√°rio inteiro como um bloco s√≥. Usaremos **Chunking Sem√¢ntico**:
* **Por Evento:** Cada consulta, exame ou nota √© um documento pai.
* **Windowing:** Se a nota for longa, dividir em janelas de 512 tokens com overlap de 50 tokens.
* **Metadata Injection:** Cada chunk deve conter o cabe√ßalho "Contexto: Dia +X, Tipo: Evolu√ß√£o" para que a IA entenda o tempo relativo.
---
## 4. Roadmap de Implementa√ß√£o (Passo a Passo)
### **Semana 1: Infraestrutura e Servi√ßo Python**
* **Tarefa 2.1: Setup do Banco (Postgres)**
* Criar migration Sequelize para habilitar `CREATE EXTENSION vector`.
* Criar tabela `rag_documents` com √≠ndices HNSW para busca r√°pida.
* **Tarefa 2.2: Setup do Microservi√ßo (Python)**
* Inicializar projeto FastAPI (`backend-ml/`).
* Configurar conex√£o com Postgres (`sqlalchemy` + `pgvector`).
* Configurar conex√£o com Ollama (verificar se `nomic-embed-text` est√° rodando).
### **Semana 2: Pipeline de Ingest√£o**
* **Tarefa 2.3: L√≥gica de Indexa√ß√£o (Python)**
* Implementar fun√ß√£o que recebe JSON.
* Configurar `LlamaIndex` para usar `OllamaEmbedding`.
* Implementar l√≥gica de processamento: JSON -> Documents -> Nodes (Chunks) -> Embeddings -> SQL.
* **Tarefa 2.4: Trigger no Node.js**
* Criar *Job* ou *Queue* no backend Node.js.
* Fluxo: Quando um prontu√°rio √© salvo/atualizado -> Chama `AnonymizationService` -> Envia JSON para `http://ml-service/ingest`.
### **Semana 3: Retrieval e Valida√ß√£o**
* **Tarefa 2.5: Endpoint de Busca H√≠brida**
* Implementar busca vetorial (dist√¢ncia cosseno).
* (Opcional para agora) Implementar filtro de palavras-chave (BM25) simples.
* **Tarefa 2.6: Teste End-to-End**
* Criar paciente "M√°rio" (fict√≠cio) com hist√≥rico de diabetes.
* Rodar ingest√£o.
* Chamar `/retrieve` com a pergunta "Qual a evolu√ß√£o da glicemia?".
* Validar se os chunks retornados correspondem aos exames de sangue do M√°rio.
---
## 5. Crit√©rios de Aceite (DoD)
1. **Privacidade Garantida:** NENHUM dado na tabela `rag_documents` cont√©m PII (Nome, CPF, etc.). Apenas o `patient_hash`.
2. **Isolamento:** Uma busca pelo `patient_hash` "A" nunca retorna dados do paciente "B".
3. **Performance:** A busca vetorial retorna resultados em < 200ms.
4. **Integridade:** O texto recuperado na busca √© id√™ntico ao texto anonimizado gerado na Fase 1.
5. **Independ√™ncia:** O servi√ßo Python roda em container separado (ou processo separado), sem acoplamento direto de c√≥digo com o Node.js.
---
## 6. Pr√≥xima A√ß√£o Imediata
Para dar in√≠cio √† Fase 2, execute o seguinte setup no seu banco de dados:
```sql
-- Habilitar extens√£o vetorial
CREATE EXTENSION IF NOT EXISTS vector;
-- Criar tabela de chunks (Compat√≠vel com LlamaIndex/PGVector)
CREATE TABLE rag_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    patient_hash VARCHAR(64) NOT NULL,
    content TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    embedding vector(768), -- Dimens√£o do nomic-embed-text
    created_at TIMESTAMP DEFAULT NOW()
);
-- Criar √≠ndice de busca
CREATE INDEX ON rag_documents USING hnsw (embedding vector_cosine_ops);
CREATE INDEX ON rag_documents (patient_hash);
```
**Podemos prosseguir com a cria√ß√£o do microservi√ßo Python (`backend-ml`)?**
A seguir est√° uma **proposta √∫nica e compacta em formato de PRD** (Product Requirements Document), consolidando as 4 propostas em um plano coerente para evoluir o **Health Guardian (HG)** para uma **‚ÄúIDE M√©dica‚Äù** (prontu√°rio = ‚Äúrepo‚Äù) com **Agentic RAG**, **rastreabilidade (trace)** e **barreira LGPD**, mantendo **ferramentas read-only**.
---
## PRD ‚Äî Health Guardian ‚ÄúIDE M√©dica‚Äù (Agentic RAG + Trace + LGPD)
### 1) Vis√£o do Produto
Transformar o HG em uma experi√™ncia semelhante a uma IDE (estilo Trae/Cursor), onde o **contexto principal √© o paciente**. O usu√°rio conversa com agentes que **buscam, abrem e citam registros do prontu√°rio**, exibindo **o que foi consultado e por qu√™**, sem alterar dados do paciente.
**Proposta de valor**
* Respostas mais √∫teis porque sempre ancoradas em **fontes do prontu√°rio** (exames, evolu√ß√µes, prescri√ß√µes, etc.).
* Transpar√™ncia e auditabilidade: **timeline/trace** de a√ß√µes (buscas, filtros, itens consultados).
* Seguran√ßa: **LGPD by design** (PII n√£o entra no √≠ndice e ferramentas s√£o somente leitura).
---
### 2) Problema
Hoje o chat com LLM tende a:
* Perder contexto do paciente em conversas longas.
* ‚ÄúResponder bonito‚Äù sem indicar quais dados reais foram usados.
* Ser dif√≠cil de auditar (o que foi consultado? qual registro?).
---
### 3) Objetivos e Resultados Esperados
**Objetivos**
1. Permitir que o usu√°rio encontre e use rapidamente informa√ß√µes do prontu√°rio (busca tipo ‚ÄúIDE search‚Äù).
2. Tornar o chat ‚ÄúRAG-first‚Äù: toda resposta importante vem com **fontes** + **itens consultados**.
3. Exibir **trace/timeline** do processo (plano resumido, tools chamadas, retrieval hits).
4. Implementar **LGPD boundary**: PII fora do √≠ndice e acessos com trilha de auditoria.
5. Criar um **Agent Registry** com agentes built-in + agentes custom (configur√°veis) com whitelist de ferramentas.
**Fora de escopo (por agora)**
* Escrita/altera√ß√£o autom√°tica em prontu√°rio (somente leitura).
* ‚ÄúChain-of-thought cru‚Äù exposto ao usu√°rio (substituir por plano resumido + log de a√ß√µes).
* Treinamento RL/RLVR (priorizar qualidade de retrieval, summaries e disciplina de ferramentas).
---
### 4) Personas e Casos de Uso
**Personas**
* **M√©dico/Cl√≠nico**: precisa navegar hist√≥rico longitudinal e tomar decis√£o r√°pida.
* **Enfermeiro/Equipe**: checar medica√ß√µes ativas, alergias, resultados recentes.
* **Auditoria/Qualidade**: precisa entender por que uma sugest√£o foi feita e com base em quais registros.
**Principais Jobs-to-be-done**
* ‚ÄúQuais foram as principais mudan√ßas nos √∫ltimos 6 meses?‚Äù
* ‚ÄúInterpretar tend√™ncia de HbA1c e correlacionar com ades√£o/medica√ß√£o.‚Äù
* ‚ÄúListar riscos/alertas: intera√ß√µes medicamentosas, alergias, doses.‚Äù
* ‚ÄúGerar resumo longitudinal com fontes rastre√°veis.‚Äù
---
### 5) Experi√™ncia do Usu√°rio (UX)
**Padr√£o de UI (inspirado em IDE)**
1. **Agents Sidebar**
   * Lista de agentes built-in (ex.: Resumidor, Exames, Seguran√ßa Medicamentosa).
   * Bot√£o **‚ÄúCreate Agent‚Äù** (agente custom) com permiss√µes e ferramentas.
2. **Chat com Transpar√™ncia**
   * Bloco colaps√°vel: **Plano/Resumo de racioc√≠nio** (curto e humano).
   * Bloco: **Itens consultados / Fontes** (ex.: ‚ÄúHemograma 12/10/2024‚Äù, ‚ÄúEvolu√ß√£o 03/11/2024‚Äù).
   * Resposta final separada.
3. **Trace/Timeline em tempo real**
   * Eventos de execu√ß√£o (busca, abrir registro, hits do retriever, verifica√ß√£o).
   * Render via SSE/WebSocket.
**Regras de transpar√™ncia (sem expor CoT)**
* Expor: `plano resumido`, `a√ß√µes`, `consultas`, `filtros`, `fontes`.
* N√£o expor: ‚Äúpensamento interno cru‚Äù do modelo.
---
### 6) Requisitos Funcionais
#### 6.1 PatientRepo (camada ‚Äúrepo do paciente‚Äù)
* Representa√ß√£o l√≥gica de documentos do paciente (n√£o precisa mudar DB atual).
* Cada item deve ter:
  * `patient_uuid` (pseudonimizado)
  * `path` (ex.: `patient/{id}/labs/2024-10-12/cbc.json`)
  * `type` (labs, note, meds, imaging‚Ä¶)
  * `date`
  * `tags` (diagn√≥sticos/s√≠ndromes/meds)
  * `content_redacted` (texto sem PII)
#### 6.2 Indexa√ß√£o e Busca (MVP Search)
* Endpoint de busca por paciente com filtros:
  * query textual, tipo, janela temporal, tags.
* Retorno deve incluir:
  * preview, path, type, date, score, highlights.
#### 6.3 Chat RAG (read-only)
* Tool `patient.search(query, filters)` retorna top-K + metadados (paths).
* Tool `patient.open(path)` retorna trecho seguro (redigido) + metadados.
* Resposta do chat deve sempre incluir:
  * **‚ÄúO que encontrei no prontu√°rio‚Äù**
  * **‚ÄúSugest√µes / hip√≥teses‚Äù**
  * **‚ÄúFontes consultadas‚Äù** (paths/datas/tipos)
#### 6.4 Agent Registry (built-in + custom)
* CRUD de agentes custom:
  * `name`, `description`, `system_prompt`, `toolsAllowed[]`, `whenToCall` (gatilhos), `callable_by_others`.
* Sele√ß√£o de agente no chat (ex.: ‚Äú@Cardio‚Äù, ‚Äú@Resumidor‚Äù).
#### 6.5 Trace Streaming
* Backend deve emitir eventos estruturados:
  * `trace.plan`
  * `tool.start`, `tool.result`
  * `retrieval.hits`
  * `final.answer`
* Frontend renderiza em timeline + blocos colaps√°veis.
---
### 7) Requisitos N√£o-Funcionais (Qualidade, Seguran√ßa, LGPD)
**LGPD by Design**
* **PII n√£o entra no √≠ndice** (reda√ß√£o antes de chunk/embedding).
* Busca sempre filtrada por `patient_uuid` (inje√ß√£o de filtro no servidor).
* Logs de auditoria: usu√°rio, paciente, tool chamada, timestamp, paths acessados.
**Seguran√ßa**
* Ferramentas somente leitura (sem write/delete).
* Controle de acesso por perfil + paciente (RBAC/ABAC).
* Rate limits e limites de contexto para evitar vazamentos acidentais.
**Performance**
* Busca deve ser r√°pida o suficiente para UX de IDE.
* Caching de retrieval e summaries quando aplic√°vel.
**Modularidade**
* Abstra√ß√µes internas para trocar:
  * provider de LLM (Ollama/local/externo),
  * retriever (pgvector/chroma/qdrant),
  * orquestrador (core pr√≥prio/LangGraph/CrewAI),
  * indexer (core pr√≥prio/LlamaIndex).
---
### 8) Arquitetura Proposta (alto n√≠vel)
**Componentes**
1. **Indexer (ETL + Redaction + Chunking + Embedding)**
2. **Store + Retriever (hybrid search + filtros obrigat√≥rios + rerank opcional)**
3. **AgentRunner (orquestra√ß√£o + tools read-only + policy)**
4. **Trace Service (event stream SSE/WebSocket)**
5. **Frontend (Agents Sidebar + Chat + Timeline + Sources)**
**Padr√£o de execu√ß√£o (ReAct/Plan-and-Act, sem expor CoT cru)**
* Plano resumido ‚Üí busca ‚Üí abrir itens necess√°rios ‚Üí compor resposta com cita√ß√µes.
---
### 9) Roadmap por Fases (entreg√°veis)
1. **Search MVP (sem agente)**
   * PatientRepo + index b√°sico + endpoint de busca + UI de resultados.
2. **Chat RAG + Sources**
   * Tool `patient.search/open` + resposta com fontes.
3. **Trace Streaming**
   * Eventos + UI colaps√°vel + timeline.
4. **Agent Registry**
   * Built-in agents + Create Agent (custom) + whitelist de tools.
5. **Hierarquia de Summaries**
   * summaries por encounter + summary longitudinal (matryoshka).
6. **Multi-agent / Committee**
   * 2‚Äì3 execu√ß√µes + √°rbitro consolidando com fontes.
7. **Otimiza√ß√µes ‚Äúdepois‚Äù (sem RL ainda)**
   * learning-to-rank no retriever via feedback/cliques.
---
### 10) M√©tricas de Sucesso
* **Ado√ß√£o**: % conversas usando tools de retrieval; % respostas com fontes.
* **Efici√™ncia**: tempo at√© achar informa√ß√£o; taxa de ‚Äúencontrei o que precisava‚Äù.
* **Qualidade**: avalia√ß√£o cl√≠nica interna; redu√ß√£o de alucina√ß√µes percebidas.
* **Compliance**: 100% de logs de acesso; 0 PII indexada.
---
### 11) Riscos e Mitiga√ß√µes
* **Vazamento de PII** ‚Üí redaction antes de index + testes automatizados + auditoria.
* **Alucina√ß√µes** ‚Üí policy ‚Äúcite-or-say-unknown‚Äù, committee/arbiter, limites de claims.
* **Performance local** ‚Üí caching, rerank opcional, summaries hier√°rquicos.
* **Confian√ßa do usu√°rio** ‚Üí transpar√™ncia via sources + trace leg√≠vel (sem CoT cru).
---
### 12) Quest√µes em Aberto
* Quais tipos de documento entram no MVP (labs/notas/meds/imaging)?
* Qual estrat√©gia de versionamento do √≠ndice e reindexa√ß√£o?
* Qual padr√£o de permiss√µes por papel (m√©dico/enfermagem/auditoria)?
* Quais agentes built-in iniciais (top 3‚Äì5) para maximizar valor?
---
Se voc√™ quiser ‚Äúoperar no modo BMad‚Äù, o caminho mais alinhado √© eu **trocar para o agente PM** e gerar um PRD no template do framework (via comando). Op√ß√µes:
1. **Voc√™ continua comigo aqui** e eu ajusto esse PRD conforme suas prioridades.
2. Voc√™ digita **`*agent pm`** para eu assumir o papel de Product Manager e refinarmos com mais rigor de backlog/aceita√ß√£o.
3. Voc√™ digita **`*workflow-guidance`** se quiser organizar isso como um projeto (brownfield/greenfield) com documenta√ß√£o completa.